AutoNERåŸºäºè¿œç¨‹ç›‘ç£çš„å®ä½“è¯†åˆ«å·¥å…·ä¸­æ–‡é€‚é…å’Œç”µåŠ›é¢†åŸŸè¯­æ–™åº”ç”¨
å¢åŠ çš„æ–‡ä»¶å¤¹å’Œæ–‡ä»¶ï¼š
1. autoner_train_standard.shï¼šä¸»ä½“è®­ç»ƒè„šæœ¬ï¼Œæ‰§è¡Œè¯»å–è¯­æ–™ã€ç”Ÿæˆè¿œç¨‹ç›‘ç£ç»“æœå’Œè®­ç»ƒè¿‡ç¨‹ï¼›
2. autoner_test_standard.shï¼šä¸»ä½“æµ‹è¯•è„šæœ¬ï¼Œæ‰§è¡Œè¯»å–æµ‹è¯•é›†å’Œæµ‹è¯•è¿‡ç¨‹ï¼›
3. get_ner_pos.pyï¼šåå¤„ç†ç¨‹åºï¼Œå°†è¾“å‡ºç»“æœä¸åŸå§‹æ–‡æ¡£å½¢æˆå¯¹åº”ï¼Œç»™å‡ºè¯†åˆ«çš„å®ä½“å’Œåœ¨åŸå§‹æ–‡æ¡£ä¸­çš„ä½ç½®ï¼›
4. Standard Preparationæ–‡ä»¶å¤¹ï¼š
  4.1 original_standard_filesæ–‡ä»¶å¤¹ï¼šç«èµ›æ‰€ç”¨ç”µåŠ›å˜å‹å™¨37ä¸ªæ ‡å‡†æ–‡ä»¶ç»è¿‡OCRåå¯¼å‡ºçš„txtæ–‡æœ¬ï¼Œåˆ†æ®µç»“æœè¿˜ä¸ç†æƒ³ï¼›
  4.2 converted_standard_filesæ–‡ä»¶å¤¹ï¼š
    4.2.1 jiebaæ–‡ä»¶å¤¹ï¼šå¯¹æ¯ä¸ªæ ‡å‡†txtè¿›è¡Œç»“å·´åˆ†è¯å†æŒ‰AutoNERè¦æ±‚æ ¼å¼è½¬åçš„ç»“æœï¼Œå•ä¸ªæ–‡ä»¶å³ä¸ºraw_text.txtï¼Œ_posä¸ºè¦æ±‚æ ¼å¼æ¯è¡Œåœ¨åŸå§‹æ ‡å‡†txtä¸­çš„ä½ç½®ï¼Œå•ä¸ªæ–‡ä»¶å³ä¸ºraw_pos.txtï¼›
    4.2.2 single_lineæ–‡ä»¶å¤¹ï¼šå°†æ¯ä¸ªæ ‡å‡†txtè½¬æ¢ä¸ºä¸€è¡Œçš„ç»“æœï¼ˆæœ¬å·¥å…·æœªä½¿ç”¨ï¼‰ï¼›
  4.3 dictionariesæ–‡ä»¶å¤¹ï¼šä¸‰ä¸ªè¯åº“æ–‡ä»¶power/transformer/mechanic_dictionary.txtï¼Œæœç‹—ä¸‹è½½çš„ç”µåŠ›ã€å˜å‹å™¨å’Œæœºæ¢°è¯åº“ï¼Œ..segmented.txtï¼Œä¸‰ä¸ªè¯åº“æ–‡ä»¶ç»ç»“å·´åˆ†è¯åç»“æœï¼Œå…¶ä¸­power_dictionary_segmented.txtå³ä¸ºdic_full.txtï¼Œä¸€ä¸ªå¸¦ç±»åˆ«è¯åº“æ–‡ä»¶ï¼Œå³ä¸ºdic_core.txtï¼›
  4.4 utilsæ–‡ä»¶å¤¹ï¼š
    4.4.1 run_jieba_on_standard.pyï¼Œè¾“å…¥4.1è·å¾—4.2.1ï¼›
    4.4.2 run_jieba_on_dict.pyï¼Œè¾“å…¥4.3è¯åº“txtè·å¾—segmented.txtï¼›
    4.4.3 toscel.py,å°†æœç‹—è¯åº“æ–‡ä»¶scelè½¬ä¸ºtxtï¼›
    4.4.4 prepare_dic_core.pyï¼Œå°†ä¸¤ä¸ªç±»åˆ«è¯åº“æ‹¼æ¥è·å¾—dic_core.txtï¼›
    4.4.5 å’Œ 4.4.6 combine_multiple_files.pyå’Œcombine_single_file.pyï¼Œå°†æ ‡å‡†txtè½¬ä¸ºä¸€è¡Œï¼ˆæœ¬å·¥å…·æœªä½¿ç”¨ï¼‰ã€‚
5. embedding/embedding.txtï¼šæ›´æ¢ä¸ºä¸­æ–‡è¯å‘é‡ã€‚
6. data/stopwords.txtï¼šæ›´æ¢ä¸ºä¸­æ–‡åœæ­¢è¯ã€‚
7. models/STANDARD/result.txtï¼šdecoded.txtæ˜¯AutoNERè‡ªèº«è¾“å‡ºç»“æœï¼Œæœ¬æ–‡ä»¶æ˜¯æ˜ å°„åˆ°åŸå§‹æ ‡å‡†txtçš„è¾“å‡ºç»“æœï¼Œæ ¼å¼ä¸ºâ€œå‘½åå®ä½“tabç±»åˆ«tabåŸå§‹æ–‡ä»¶è¡Œtabè¡Œå†…èµ·å§‹ä½ç½®tabç»ˆæ­¢ä½ç½®â€ã€‚

æ•´ä½“ä½¿ç”¨æµç¨‹ï¼š
1. æ‰§è¡Œrun_jieba_on_standard.pyï¼Œè·å¾—raw_text.txtå’Œraw_pos.txtï¼›
2. æ‰§è¡Œtoscel.pyã€run_jieba_on_dict.pyå’Œprepare_dic_core.pyï¼Œè·å¾—dic_full.txtå’Œdic_core.txt;
3. ä» https://pan.baidu.com/s/1XEmP_0FkQwOjipCjI2OPEw ä¸‹è½½word2vec skip-gram negative sampling 300dä¸­æ–‡è¯å‘é‡ï¼Œåˆ é™¤ç¬¬ä¸€è¡Œï¼Œè·å¾—embedding.txtç½®äºembeddingæ–‡ä»¶å¤¹ä¸­ï¼Œä» https://github.com/goto456/stopwords/blob/master/baidu_stopwords.txt ä¸‹è½½baidu_stopwordsï¼Œæ›¿æ¢dataæ–‡ä»¶å¤¹ä¸‹çš„stopwords.txtï¼›
4. æ‰§è¡Œautoner_train_standard.shï¼Œè·å¾—è¿œç¨‹ç›‘ç£ç»“æœå’Œè®­ç»ƒæ¨¡å‹ï¼›
5.æ‰§è¡Œautoner_test_standard.shï¼Œè·å¾—è¾“å‡ºç»“æœå’Œå‡†ç¡®ç‡ï¼ˆç›®å‰æµ‹è¯•é›†ä½¿ç”¨è¿œç¨‹ç›‘ç£ç»“æœï¼‰ï¼›
6.æ‰§è¡Œget_ner_pos.pyï¼Œè·å¾—åå¤„ç†çš„è¾“å‡ºç»“æœã€‚

debugè®°å½•ï¼š
å¯¹åŸå§‹AutoNERå·¥å…·çš„ä»£ç åšäº†å¦‚ä¸‹ä¿®æ”¹ï¼Œ
1. auto_ner_train.shï¼šä¿®æ”¹è¾“å‡ºæ¨¡å‹æ–‡ä»¶å¤¹å’Œå››ä¸ªè¾“å…¥æ–‡ä»¶çš„è·¯å¾„ï¼Œå°†æµ‹è¯•é›†æ›´æ¢ä¸ºè¿œç¨‹ç›‘ç£ç»“æœï¼Œä¿®æ”¹embeddingç»´æ•°ä¸º300ï¼›
2. auto_ner_test.shï¼šä¿®æ”¹æµ‹è¯•è·¯å¾„å’Œembeddingç»´æ•°ã€‚
3. encode_folder.pyï¼šé»˜è®¤éªŒè¯é›†ä¸º3æ®µæ ¼å¼ï¼Œå®é™…ç”¨è¿œç¨‹ç›‘ç£ç»“æœæ›¿ä»£æ‰€ä»¥æ˜¯4æ®µï¼Œä¿®æ”¹äº†ä»£ç ï¼›
4. dataset.pyï¼šByteTensoråœ¨æœ€æ–°PyTorchç‰ˆæœ¬ä¸­è¿‡æ—¶ï¼Œæ¢ä¸ºBoolTypeã€‚

ç»“æœå’Œç»“è®ºï¼š
1. ç›®å‰ï¼Œå°†è¿œç¨‹ç›‘ç£ç»“æœä½œä¸ºæµ‹è¯•é›†çš„F1ä¸º0.648ã€‚
2. è§‚å¯Ÿè¾“å‡ºç»“æœï¼Œå®ä½“æ ‡æ³¨å‡†ç¡®ç‡å¾ˆé«˜ï¼Œå¬å›ç‡è¾ƒä½ï¼Œè§‚å¯Ÿè¿œç¨‹ç›‘ç£ç»“æœï¼Œä¹Ÿå­˜åœ¨å‡†ç¡®ç‡è¾ƒé«˜ä½†å¬å›ç‡è¾ƒä½çš„æƒ…å†µã€‚
3. æ–¹æ³•æ¯”è¾ƒæœ‰æ½œåŠ›ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–éœ€è¦æå‡ï¼ˆ1ï¼‰embeddingè¦†ç›–çš„è¯æ•°ï¼Œï¼ˆ2ï¼‰raw_textçš„è§„æ¨¡ï¼Œï¼ˆ3ï¼‰dic_coreçš„ç±»åˆ«å’Œè¯æ•°ï¼Œï¼ˆ4ï¼‰æ‰‹å·¥æ ‡æ³¨ä¸€äº›éªŒè¯é›†ï¼Œå¸®åŠ©æ¨¡å‹æ‰¾åˆ°åˆé€‚çš„è®­ç»ƒåœæ­¢ç‚¹ã€‚

---------------Original Readme-----------------
# AutoNER

**Check Our New NER ToolkitğŸš€ğŸš€ğŸš€**
- **Inference**:
  - **[LightNER](https://github.com/LiyuanLucasLiu/LightNER)**: inference w. models pre-trained / trained w. *any* following tools, *efficiently*. 
- **Training**:
  - **[LD-Net](https://github.com/LiyuanLucasLiu/LD-Net)**: train NER models w. efficient contextualized representations.
  - **[VanillaNER](https://github.com/LiyuanLucasLiu/Vanilla_NER)**: train vanilla NER models w. pre-trained embedding.
- **Distant Training**:
  - **[AutoNER](https://shangjingbo1226.github.io/AutoNER/)**: train NER models w.o. line-by-line annotations and get competitive performance.

--------------------------------

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Documentation Status](https://readthedocs.org/projects/autoner/badge/?version=latest)](http://autoner.readthedocs.io/en/latest/?badge=latest)

**No line-by-line annotations**, AutoNER trains named entity taggers with distant supervision.

Details about AutoNER can be accessed at: [https://arxiv.org/abs/1809.03599](https://arxiv.org/abs/1809.03599)

- [Model notes](#model-notes)
- [Benchmarks](#benchmarks)
- [Training](#training)
	- [Required Inputs](#required-inputs)
	- [Dependencies](#dependencies)
	- [Command](#command)
- [Citation](#citation)

## Model Notes

![AutoNER-Framework](docs/AutoNER-Framework.png)

## Benchmarks

| Method | Precision | Recall | F1 |
| ------------- |-------------| -----| -----|
| Supervised Benchmark | 88.84 | 85.16 | **86.96** |
| Dictionary Match | 93.93 | 58.35 | 71.98 |
| Fuzzy-LSTM-CRF | 88.27 | 76.75 | 82.11 |
| AutoNER | 88.96 | 81.00 | **84.80** |

## Training

### Required Inputs

- **Tokenized Raw Texts**
  - Example: ```data/BC5CDR/raw_text.txt```
    - One token per line.
    - An empty line means the end of a sentence.
- **Two Dictionaries**
  - **Core Dictionary w/ Type Info**
    - Example: ```data/BC5CDR/dict_core.txt```
      - Two columns (i.e., Type, Tokenized Surface) per line.
      - Tab separated.
    - How to obtain?
      - From domain-specific dictionaries.
  - **Full Dictionary w/o Type Info**
    - Example: ```data/BC5CDR/dict_full.txt```
      - One tokenized high-quality phrases per line.
    - How to obtain? 
      - From domain-specific dictionaries.
      - Applying the high-quality phrase mining tool on domain-specific corpus.
        - [AutoPhrase](https://github.com/shangjingbo1226/AutoPhrase) 
- **Pre-trained word embeddings**
  - Train your own or download from the web.
  - The example run uses ```embedding/bio_embedding.txt```, which can be downloaded from [our group's server](http://dmserv4.cs.illinois.edu/bio_embedding.txt). For example, ```curl http://dmserv4.cs.illinois.edu/bio_embedding.txt -o embedding/bio_embedding.txt```. Since the embedding encoding step consumes quite a lot of memory, we also provide the encoded file in the ```autoner_train.sh```.
- **[Optional]** Development & Test Sets.
  - Example: ```data/BC5CDR/truth_dev.ck``` and ```data/BC5CDR/truth_test.ck```
    - Three columns (i.e., token, ```Tie or Break``` label, entity type).
    - ```I``` is ```Break```.
    - ```O``` is ```Tie```.
    - Two special tokens ```<s>``` and ```<eof>``` mean the start and end of the sentence.

### Dependencies

This project is based on ```python>=3.6```. The dependent package for this project is listed as below:
```
numpy==1.13.1
tqdm
torch-scope>=0.5.0
pytorch==0.4.1
```

### Command

To train an AutoNER model, please run
```
./autoner_train.sh
```

To apply the trained AutoNER model, please run
```
./autoner_test.sh
```

You can specify the parameters in the bash files. The variables names are self-explained.


## Citation

Please cite the following two papers if you are using our tool. Thanks!

- Jingbo Shang*, Liyuan Liu*, Xiaotao Gu, Xiang Ren, Teng Ren and Jiawei Han, "**[Learning Named Entity Tagger using Domain-Specific Dictionary](https://arxiv.org/abs/1809.03599)**", in Proc. of 2018 Conf. on Empirical Methods in Natural Language Processing (EMNLP'18), Brussels, Belgium, Oct. 2018. (* Equal Contribution)
- Jingbo Shang, Jialu Liu, Meng Jiang, Xiang Ren, Clare R Voss, Jiawei Han, "**[Automated Phrase Mining from Massive Text Corpora](https://arxiv.org/abs/1702.04457)**", accepted by IEEE Transactions on Knowledge and Data Engineering, Feb. 2018.

```
@inproceedings{shang2018learning,
  title = {Learning Named Entity Tagger using Domain-Specific Dictionary}, 
  author = {Shang, Jingbo and Liu, Liyuan and Ren, Xiang and Gu, Xiaotao and Ren, Teng and Han, Jiawei}, 
  booktitle = {EMNLP}, 
  year = 2018, 
}

@article{shang2018automated,
  title = {Automated phrase mining from massive text corpora},
  author = {Shang, Jingbo and Liu, Jialu and Jiang, Meng and Ren, Xiang and Voss, Clare R and Han, Jiawei},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  year = {2018},
  publisher = {IEEE}
}
```
